{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\дом.DESKTOP-A3U9TO1\\AppData\\Local\\Temp\\ipykernel_13036\\2303112630.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=\"C:\\\\Users\\\\дом.DESKTOP-A3U9TO1\\\\DataspellProjects\\\\moretech_prokhodilimimo\\\\chromedriver\\\\chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: unable to connect to renderer\n  (failed to check if window was closed: disconnected: unable to connect to renderer)\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00DF1ED3+2236115]\n\tOrdinal0 [0x00D892F1+1807089]\n\tOrdinal0 [0x00C966FD+812797]\n\tOrdinal0 [0x00C8798A+752010]\n\tOrdinal0 [0x00C7C754+706388]\n\tOrdinal0 [0x00C7D564+709988]\n\tOrdinal0 [0x00CEA655+1156693]\n\tOrdinal0 [0x00CE1A53+1120851]\n\tOrdinal0 [0x00CBA73D+960317]\n\tOrdinal0 [0x00CBB71F+964383]\n\tGetHandleVerifier [0x0109E7E2+2743074]\n\tGetHandleVerifier [0x010908D4+2685972]\n\tGetHandleVerifier [0x00E82BAA+532202]\n\tGetHandleVerifier [0x00E81990+527568]\n\tOrdinal0 [0x00D9080C+1837068]\n\tOrdinal0 [0x00D94CD8+1854680]\n\tOrdinal0 [0x00D94DC5+1854917]\n\tOrdinal0 [0x00D9ED64+1895780]\n\tBaseThreadInitThunk [0x75E16739+25]\n\tRtlGetFullPathName_UEx [0x77158FD2+1218]\n\tRtlGetFullPathName_UEx [0x77158F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mWebDriverException\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(e)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m----> 9\u001B[0m     \u001B[43mdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     driver\u001B[38;5;241m.\u001B[39mquit()\n",
      "File \u001B[1;32mC:\\anaconda\\envs\\moretech_prokhodilimimo\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:551\u001B[0m, in \u001B[0;36mWebDriver.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclose\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    543\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;124;03m    Closes the current window.\u001B[39;00m\n\u001B[0;32m    545\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;124;03m            driver.close()\u001B[39;00m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 551\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCommand\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCLOSE\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\anaconda\\envs\\moretech_prokhodilimimo\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[1;34m(self, driver_command, params)\u001B[0m\n\u001B[0;32m    427\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_executor\u001B[38;5;241m.\u001B[39mexecute(driver_command, params)\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[1;32m--> 429\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    430\u001B[0m     response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unwrap_value(\n\u001B[0;32m    431\u001B[0m         response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    432\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mC:\\anaconda\\envs\\moretech_prokhodilimimo\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001B[0m, in \u001B[0;36mErrorHandler.check_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    241\u001B[0m         alert_text \u001B[38;5;241m=\u001B[39m value[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124malert\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001B[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001B[39;00m\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001B[1;31mWebDriverException\u001B[0m: Message: disconnected: unable to connect to renderer\n  (failed to check if window was closed: disconnected: unable to connect to renderer)\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00DF1ED3+2236115]\n\tOrdinal0 [0x00D892F1+1807089]\n\tOrdinal0 [0x00C966FD+812797]\n\tOrdinal0 [0x00C8798A+752010]\n\tOrdinal0 [0x00C7C754+706388]\n\tOrdinal0 [0x00C7D564+709988]\n\tOrdinal0 [0x00CEA655+1156693]\n\tOrdinal0 [0x00CE1A53+1120851]\n\tOrdinal0 [0x00CBA73D+960317]\n\tOrdinal0 [0x00CBB71F+964383]\n\tGetHandleVerifier [0x0109E7E2+2743074]\n\tGetHandleVerifier [0x010908D4+2685972]\n\tGetHandleVerifier [0x00E82BAA+532202]\n\tGetHandleVerifier [0x00E81990+527568]\n\tOrdinal0 [0x00D9080C+1837068]\n\tOrdinal0 [0x00D94CD8+1854680]\n\tOrdinal0 [0x00D94DC5+1854917]\n\tOrdinal0 [0x00D9ED64+1895780]\n\tBaseThreadInitThunk [0x75E16739+25]\n\tRtlGetFullPathName_UEx [0x77158FD2+1218]\n\tRtlGetFullPathName_UEx [0x77158F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://google.com\"\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\\\Users\\\\дом.DESKTOP-A3U9TO1\\\\DataspellProjects\\\\moretech_prokhodilimimo\\\\chromedriver\\\\chromedriver.exe\")\n",
    "try:\n",
    "    driver.get(url=url)\n",
    "    time.sleep(10)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    driver.close()\n",
    "    driver.quit()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "#URL = 'https://www.rbc.ru/neweconomy/'\n",
    "URL = 'https://www.rbc.ru/'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    r = requests.get(url).text\n",
    "    return BeautifulSoup(r, 'lxml')\n",
    "\n",
    "\n",
    "def save_json(data):\n",
    "    with open('rbk_data1.json', \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def main():\n",
    "    news_data = {}\n",
    "\n",
    "    soup = get_soup(URL)\n",
    "\n",
    "    # Получаем все ссылки на новости\n",
    "    news_links = soup.find('div', class_='main').find_all('a', {'class': ['main__big__link', 'main__feed__link']})\n",
    "\n",
    "    # Для каждой ссылки получаем информацию и записываем в news_data\n",
    "    for i in range(12):\n",
    "\n",
    "        link = news_links[i].get('href').split('?')[0]\n",
    "        name = link\n",
    "        news_data[name] = {}\n",
    "        soup = get_soup(link)\n",
    "\n",
    "        # Переходим на страницу для дальнейшенго парсинга\n",
    "        article = soup.find('div', class_='article')\n",
    "        #print(article.find('a'))\n",
    "        category = article.find('a', class_='article__header__category')\n",
    "\n",
    "        #date = article.find('span', class_='article__header__date').get('content').replace('T', ' ').split('+')[0]\n",
    "        title = article.find('span', class_='js-slide-title')\n",
    "        image = article.find('div', class_='article__main-image')\n",
    "\n",
    "        article_paragraphs = article.find_all('p')\n",
    "        article_text = ''\n",
    "        for paragraph in article_paragraphs:\n",
    "            article_text += paragraph.text\n",
    "\n",
    "        # Заполняем полученными данными news_data\n",
    "        news_data[name]['link'] = link\n",
    "        #news_data[name]['date'] = date\n",
    "        news_data[name]['text'] = article_text.replace('\\xa0', '').replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "        try:\n",
    "            news_data[name]['title'] = title.text\n",
    "        except AttributeError:\n",
    "            news_data[name]['title'] = 'Без заголовка'\n",
    "        try:\n",
    "            news_data[name]['category'] = category.text.replace('\\n', '')\n",
    "        except AttributeError:\n",
    "            news_data[name]['category'] = 'Без категории'\n",
    "        try:\n",
    "            news_data[name]['image'] = image.find('img').get('src')\n",
    "        except AttributeError:\n",
    "            news_data[name]['image'] = 'Без обложки'\n",
    "\n",
    "    save_json(news_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07.10.2022\n",
      "07.10.2022\n",
      "07.10.2022\n",
      "07.10.2022\n",
      "06.10.2022\n",
      "04.10.2022\n",
      "04.10.2022\n",
      "03.10.2022\n",
      "28.09.2022\n",
      "29.09.2022\n",
      "29.09.2022\n",
      "27.09.2022\n",
      "28.09.2022\n",
      "26.09.2022\n",
      "26.09.2022\n",
      "20.09.2022\n",
      "16.09.2022\n",
      "14.09.2022\n",
      "15.09.2022\n",
      "07.09.2022\n",
      "06.09.2022\n",
      "01.09.2022\n",
      "29.08.2022\n",
      "25.08.2022\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "URL = 'https://www.rbc.ru/neweconomy/'\n",
    "#URL = 'https://www.rbc.ru/'\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    r = requests.get(url).text\n",
    "    return BeautifulSoup(r, 'lxml')\n",
    "\n",
    "\n",
    "def save_json(data):\n",
    "    with open('rbk_data.json', \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def main():\n",
    "    news_data = {}\n",
    "\n",
    "    soup = get_soup(URL)\n",
    "\n",
    "    # Получаем все ссылки на новости\n",
    "    #print(soup.find_all('a', {'class' : ['q-item__link', ]}))\n",
    "\n",
    "    news_links = soup.find_all('a', {'class' : ['q-item__link', ]})\n",
    "\n",
    "    # Для каждой ссылки получаем информацию и записываем в news_data\n",
    "    for i in range(len(news_links)):\n",
    "\n",
    "        link = news_links[i].get('href').split('?')[0]\n",
    "        name = link\n",
    "        news_data[name] = {}\n",
    "        soup = get_soup(link)\n",
    "        #print(soup.text)\n",
    "\n",
    "        # Переходим на страницу для дальнейшенго парсинга\n",
    "        article = soup.find('div', class_='article')\n",
    "        #print(article)\n",
    "\n",
    "        #print(article.find('a'))\n",
    "        #category = article.find('a', class_='article__header__category')\n",
    "        #date = article.find('span', class_='atricle__date-update').get('content').replace('T', ' ').split('+')[0]\n",
    "        try:\n",
    "            date = soup.find('div', class_='atricle__date-update').get_text().strip().split()[1]\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        print(date)\n",
    "        title = soup.title\n",
    "        #image = article.find('div', class_='article__main-image')\n",
    "        try:\n",
    "            article_paragraphs = article.find_all('p')\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        article_text = ''\n",
    "        for paragraph in article_paragraphs:\n",
    "            article_text += paragraph.text\n",
    "        #print(article_text)\n",
    "\n",
    "        # Заполняем полученными данными news_data\n",
    "        news_data[name]['link'] = link\n",
    "        news_data[name]['date'] = date\n",
    "        news_data[name]['text'] = article_text.replace('\\xa0', '').replace('\\n', '').replace('\\r', '')\n",
    "\n",
    "        try:\n",
    "            news_data[name]['title'] = title.text\n",
    "        except AttributeError:\n",
    "            news_data[name]['title'] = 'Без заголовка'\n",
    "        #try:\n",
    "            #news_data[name]['category'] = category.text.replace('\\n', '')\n",
    "        #except AttributeError:\n",
    "            #news_data[name]['category'] = 'Без категории'\n",
    "        #try:\n",
    "            #news_data[name]['image'] = image.find('img').get('src')\n",
    "        #except AttributeError:\n",
    "            #news_data[name]['image'] = 'Без обложки'\n",
    "\n",
    "    save_json(news_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
